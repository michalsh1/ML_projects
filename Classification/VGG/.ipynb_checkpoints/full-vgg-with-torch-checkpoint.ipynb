{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cc35ad75fffbed0d6e0533180dbf9b660acf2b97"
   },
   "source": [
    "## Parameters\n",
    "Try to keep the model parameters and configurations all in one cell to make it easier to keep track of (and automate later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "282dfd9a5c4388b3e71b344f7e3485b5dbe88f95"
   },
   "outputs": [],
   "source": [
    "TEST_SPLIT = 0.25\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "MICRO_DATA = False # very small subset (just 3 groups)\n",
    "SAMPLE_TRAINING = False # make train set smaller for faster iteration\n",
    "IMG_SIZE = (224, 224)\n",
    "LEARNING_RATE = 4e-3\n",
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d6559e5aaf452ddb945964fd6a76d54dda0ba803"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "torch.manual_seed(42) # try and make the results more reproducible\n",
    "BASE_PATH = os.path.join('..', 'input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ea20e1944fdc24a8dd36034871e39acdf80b9a14"
   },
   "source": [
    "## Create Dataset\n",
    "Here we find all of the files and organize them into categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f3851dc02fc8fed1de7c3e11c7201b259da3388"
   },
   "outputs": [],
   "source": [
    "all_img_df = pd.DataFrame({'path':\n",
    "                           glob(os.path.join(BASE_PATH, 'images', '*', '*.jpg'))})\n",
    "all_img_df['category'] = all_img_df['path'].map(lambda x: \n",
    "                                                os.path.split(os.path.dirname(x))[-1].replace('_', ' '))\n",
    "if MICRO_DATA:\n",
    "    all_img_df = all_img_df[all_img_df['category'].isin(['samosa', 'gnocchi', 'hot dog'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "736b65c893c058daeb9c0a8176869513a3519346"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cat_enc = LabelEncoder()\n",
    "all_img_df['cat_idx'] = cat_enc.fit_transform(all_img_df['category'])\n",
    "N_CLASSES = len(cat_enc.classes_)\n",
    "print(N_CLASSES, 'classes')\n",
    "all_img_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "06d328ce95cecc83390e1c5e83915a6a315bb74a"
   },
   "source": [
    "# Data Loading Classes\n",
    "Here are the classes to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class DataWrapper(data.Dataset):\n",
    "    ''' Data wrapper for pytorch's data loader function '''\n",
    "    def __init__(self, image_df, resize):\n",
    "        self.dataset = image_df\n",
    "        self.resize = resize\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        c_row = self.dataset.iloc[index]\n",
    "        image_path, target = c_row['path'], c_row['cat_idx']  #image and target\n",
    "        #read as rgb image, resize and convert to range 0 to 1\n",
    "        image = cv2.imread(image_path, 1)\n",
    "        if self.resize:\n",
    "            image = cv2.resize(image, IMG_SIZE)/255.0 \n",
    "        else:\n",
    "            image = image/255.0\n",
    "        image = (torch.from_numpy(image.transpose(2,0,1))).float() #NxCxHxW\n",
    "        return image, int(target)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1cfe0c93051156559a7057446c6333babec61a69"
   },
   "source": [
    "## Split data into a train/test group\n",
    "We can also shrink the size of the training group to make it quicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3e564bc66df41989a99dd6b6fa7719c59e76eb9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(all_img_df, \n",
    "                                     test_size=TEST_SPLIT, \n",
    "                                     random_state=42,\n",
    "                                     stratify=all_img_df['category'])\n",
    "\n",
    "if SAMPLE_TRAINING: # make train smaller for faster testing\n",
    "    train_df = train_df.\\\n",
    "        groupby('category').\\\n",
    "        apply(lambda x: x.sample(50)).\\\n",
    "        reset_index(drop=True).\\\n",
    "        sample(frac=1).\\\n",
    "        reset_index(drop=True)\n",
    "print('train', train_df.shape[0], 'test', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6207f36100d6de3a9dc57b8da1e645729dcd4e3e"
   },
   "outputs": [],
   "source": [
    "train_dataset = DataWrapper(train_df, True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,shuffle=True, \n",
    "            batch_size=batch_size, pin_memory=False)#, num_workers=4)\n",
    "\n",
    "test_dataset = DataWrapper(test_df, True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,shuffle=True, \n",
    "            batch_size=batch_size, pin_memory=False) #num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4eee13da070cb3f6f13607d008c4e493232e580"
   },
   "source": [
    "# Build the VGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "78c9e6728ab27d22d62d69c994418aad0088e90f"
   },
   "outputs": [],
   "source": [
    "class ConvBnReLu(nn.Module):\n",
    "    '''Repetitive block of conv->batch norm->relu'''\n",
    "    def __init__(self,in_planes,out_planes,drop=0.0,kernel=3,padding=1,stride=1):\n",
    "        super(ConvBnReLu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=3, \n",
    "                                          stride=stride, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop = nn.Dropout(p=drop)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return self.drop(self.relu(x))\n",
    "    \n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    '''Simple 3x3 convolution'''\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, \n",
    "                              stride=stride, padding=1)\n",
    "\n",
    "class VGGNet(nn.Module):\n",
    "    def __init__(self,num_feat=16,num_class=N_CLASSES):\n",
    "        \"\"\"Define the components of a VGG 11 model\"\"\"\n",
    "        super(VGGNet, self).__init__()     \n",
    "        self.num_feat = num_feat\n",
    "        self.conv_1 = conv3x3(3,num_feat)\n",
    "        self.conv_2 = conv3x3(num_feat,2*num_feat)\n",
    "        self.conv_3_1 = conv3x3(2*num_feat,4*num_feat)\n",
    "        self.conv_3_2 = conv3x3(4*num_feat,4*num_feat)\n",
    "        self.conv_4_1 = conv3x3(4*num_feat,8*num_feat)\n",
    "        self.conv_4_2 = conv3x3(8*num_feat,8*num_feat)\n",
    "        self.conv_5_1 = conv3x3(8*num_feat,8*num_feat)\n",
    "        self.conv_5_2 = conv3x3(8*num_feat,2*num_feat)\n",
    "\n",
    "        self.fc1 = nn.Linear((2*num_feat)*7*7,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.pred = nn.Linear(256,num_class)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"Input x is expected to be a 4d tensor (N x C X H x W)\n",
    "           N - Number of images in minibatch\n",
    "           C - Number of channels\n",
    "           H,W  - Height and Width of image, respectively \"\"\"\n",
    "\n",
    "        conv_1 = self.conv_1(x)\n",
    "        relu_1 = self.relu(conv_1)\n",
    "        pool_1 = self.max_pool(relu_1)\n",
    "\n",
    "        conv_2 = self.conv_2(pool_1)\n",
    "        relu_2 = self.relu(conv_2)\n",
    "        pool_2 = self.max_pool(relu_2)\n",
    "\n",
    "        conv_3_1 = self.conv_3_1(pool_2)\n",
    "        relu_3_1 = self.relu(conv_3_1)\n",
    "        conv_3_2 = self.conv_3_2(relu_3_1)\n",
    "        relu_3_2 = self.relu(conv_3_2)\n",
    "        pool_3 = self.max_pool(relu_3_2)\n",
    "\n",
    "        conv_4_1 = self.conv_4_1(pool_3)\n",
    "        relu_4_1 = self.relu(conv_4_1)\n",
    "        conv_4_2 = self.conv_4_2(relu_4_1)\n",
    "        relu_4_2 = self.relu(conv_4_2)\n",
    "        pool_4 = self.max_pool(relu_4_2)\n",
    "\n",
    "        conv_5_1 = self.conv_5_1(pool_4)\n",
    "        relu_5_1 = self.relu(conv_5_1)\n",
    "        conv_5_2 = self.conv_5_2(relu_5_1)\n",
    "        relu_5_2 = self.relu(conv_5_2)\n",
    "        pool_5 = self.max_pool(relu_5_2)\n",
    "\n",
    "        fc1 = self.relu(self.fc1(pool_5.view(-1,(2*self.num_feat)*7*7)))\n",
    "        fc2 = self.relu(self.fc2(fc1))\n",
    "\n",
    "        return self.pred(fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "babc75ea2ff1661c9628b15a3e6933e0b47b07cf"
   },
   "source": [
    "# Build and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db1ca24dab1501309366f0a9cef0b6c2c326d4e4"
   },
   "outputs": [],
   "source": [
    "model = VGGNet().to(device) #VGG style model\n",
    "criterion = nn.CrossEntropyLoss() #Use cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76e06bae374b903cbada471ba59154eea04bba0d"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "425fd7a7c6559dafd81ee577729c15115603cdf1"
   },
   "outputs": [],
   "source": [
    "# nice wait bars\n",
    "from tqdm import tqdm_notebook, tnrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7da72c9389c9d84b29219e7a6dfba8679e9b3a51"
   },
   "source": [
    "# Train for given number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "302fd53900f9e7efe66e77efc6d8864ff9bd56ba"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.display import clear_output, display\n",
    "train_results = defaultdict(list)\n",
    "train_iter, test_iter, best_acc = 0,0,0\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize = (10, 10))\n",
    "ax1.set_title('Train Loss')\n",
    "ax2.set_title('Train Accuracy')\n",
    "ax3.set_title('Test Loss')\n",
    "ax4.set_title('Test Accuracy')\n",
    "\n",
    "for i in tnrange(epochs, desc='Epochs'):\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "    print(\"Epoch \",i)\n",
    "    ## Train Phase\n",
    "    #Model switches to train phase\n",
    "    model.train() \n",
    "    \n",
    "    # Running through all mini batches in the dataset\n",
    "    count, loss_val, correct, total = train_iter, 0, 0, 0\n",
    "    for data, target in tqdm_notebook(train_loader, desc='Training'):    \n",
    "        if use_gpu: #Using GPU & Cuda\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data) #FWD prop\n",
    "        loss = criterion(output, target) #Cross entropy loss\n",
    "        c_loss = loss.data.item()\n",
    "        ax1.plot(count, c_loss, 'r.')\n",
    "        loss_val += c_loss\n",
    "\n",
    "        optimizer.zero_grad() #Zero out any cached gradients\n",
    "        loss.backward() #Backward pass\n",
    "        optimizer.step() #Update the weights\n",
    "\n",
    "        #Compute accuracy\n",
    "        predicted = output.data.max(1)[1] #get index of max\n",
    "        total += target.size(0) #total samples in mini batch\n",
    "        c_acc = (predicted == target).sum().item()\n",
    "        ax2.plot(count, c_acc/target.size(0), 'r.')\n",
    "        correct += c_acc\n",
    "        count +=1\n",
    "    train_loss_val, train_iter, train_acc = loss_val/len(train_loader.dataset), count, correct/float(total)\n",
    "    \n",
    "    print(\"Training loss: \", train_loss_val, \" train acc: \",train_acc)    \n",
    "    ## Test Phase\n",
    "    \n",
    "    #Model switches to test phase\n",
    "    model.eval()\n",
    "\n",
    "    #Running through all mini batches in the dataset\n",
    "    count, correct, total, lost_val = test_iter, 0, 0, 0\n",
    "    for data, target in tqdm_notebook(test_loader, desc='Testing'):\n",
    "        if use_gpu: #Using GPU & Cuda\n",
    "            data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target) #Cross entropy loss\n",
    "        c_loss = loss.data.item()\n",
    "        ax3.plot(count, c_loss, 'b.')\n",
    "        loss_val += c_loss\n",
    "        #Compute accuracy\n",
    "        predicted = output.data.max(1)[1] #get index of max\n",
    "        total += target.size(0) #total samples in mini batch\n",
    "        c_acc = (predicted == target).sum().item()\n",
    "        ax4.plot(count, c_acc/target.size(0), 'b.')\n",
    "        correct += c_acc\n",
    "        count += 1\n",
    "\n",
    "    #Accuracy over entire dataset\n",
    "    test_acc, test_iter, test_loss_val = correct/float(total), count, loss_val/len(test_loader.dataset)\n",
    "    print(\"Epoch: \",i,\" test set accuracy: \",test_acc)\n",
    "    \n",
    "    train_results['epoch'].append(i)\n",
    "    train_results['train_loss'].append(train_loss_val)\n",
    "    train_results['train_acc'].append(train_acc)\n",
    "    train_results['train_iter'].append(train_iter)\n",
    "    \n",
    "    train_results['test_loss'].append(test_loss_val)\n",
    "    train_results['test_acc'].append(test_acc)\n",
    "    train_results['test_iter'].append(test_iter)\n",
    "    \n",
    "    #Save model with best accuracy\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth') \n",
    "plt.show()\n",
    "fig.savefig('train.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "afd4d321ef0ad9c016467e94b17ac421e6db714d"
   },
   "outputs": [],
   "source": [
    "train_results_df = pd.DataFrame(train_results)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "train_results_df.plot('epoch', ['train_loss', 'test_loss'], ax=ax1)\n",
    "ax1.set_title('Loss')\n",
    "train_results_df.plot('epoch', ['train_acc', 'test_acc'], ax=ax2)\n",
    "ax2.set_title('Accuracy')\n",
    "fig.savefig('epochs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e32eb51f8c38c0bd4828cab7f2d1fa45422e50d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
